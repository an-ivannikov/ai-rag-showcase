# AI RAG Showcase
This repository is a **showcase project** demonstrating **Retrieval-Augmented Generation (RAG)** using different datasets.  
It highlights how RAG can be applied to multiple domains: programming documentation, custom datasets, and even synthetic (fictional) data.

---


## Features
  - Universal **backend** in Node.js/TypeScript (Express).
  - **Qdrant** as the vector database for embeddings.
  - **Worker service** for ingestion (document parsing + embeddings).
  - **Telegram bot** built with [telegraf.js](https://github.com/telegraf/telegraf).
  - **Next.js web app** for testing queries and managing datasets.
  - Easily extensible: just drop a new dataset into `datasets/` and re-ingest.

---


## Project Structure
```
ai-rag-showcase/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # RAG API (Express).
â”‚   â”œâ”€â”€ tg-bot/           # Telegram bot (telegraf.js).
â”‚   â”œâ”€â”€ web/              # Next.js panel.
â”‚   â””â”€â”€ worker/           # Ingestion worker (BullMQ + Redis).
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ mythlang/         # Fictional "MythLang" programming language.
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/             # Shared RAG pipeline logic.
â”‚   â”œâ”€â”€ embeddings/       # Embeddings providers (OpenAI/local).
â”‚   â”œâ”€â”€ llm/              # LLM providers (OpenAI/Ollama).
â”‚   â”œâ”€â”€ utils/            # Config, logger, helpers.
â”‚   â””â”€â”€ vectorstore/      # Qdrant wrapper.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---


## Datasets Included
  - **MythLang** â†’ a **fictional programming language for spells and rituals** (synthetic dataset).

---


## Tech Stack
  - **TypeScript**
  - **MERN** â†’ MongoDB, Express.js, React/Next.js, Node.js.
  - **Qdrant** â†’ Vector database for embeddings.
  - **Redis + BullMQ** â†’ Job queue for ingestion.
  - **OpenAI API** â†’ Embeddings + LLM (GPT-4o-mini).
  - **telegraf.js** â†’ Telegram bot.

---


## Quick Start
```bash
git clone https://github.com/an-ivannikov/ai-rag-showcase
cd ai-rag-showcase

# Install dependencies
pnpm install

# Copy env file
cp .env.example .env

# Start vector DB + Redis + Mongo
docker compose --profile infra  --profile app build --no-cache
docker compose --profile infra  --profile app up --force-recreate -d

# Run backend + worker + bot
pnpm dev

curl -X POST http://localhost:3001/ingest \
  -H "Content-Type: application/json" \
  -d '{"dir":"./datasets/mythlang","meta":{"source":"mythlang_docs","lang":"en"}}'
```

---


## Example Interaction

**User:**  
```text
> How do I declare a function in MythLang?
```

**Bot:**  
```text
ðŸ’¡ Answer
Functions are declared using the ritual keyword. For example:
ritual functionName(parameters) {
  // function code here
}


You can refer to the "MythLang Syntax" chapter for more details.

ðŸ“– Sources
#1 intro.md 0 (score 0.680)
#2 syntax.md 0 (score 0.672)
#3 examples.md 0 (score 0.611)
```

---


## Architecture
![architecture.svg](architecture.svg "architecture.svg").

---


## Purpose
This project is not meant as a production-ready system.
Itâ€™s a **portfolio showcase** to demonstrate:
  - Understanding of **RAG pipelines**.
  - Integration with **Telegram bots**.
  - Handling multiple datasets (real + synthetic).
  - Modern **MERN + vector DB** stack.

---


## License
MIT â€” feel free to fork and adapt.
